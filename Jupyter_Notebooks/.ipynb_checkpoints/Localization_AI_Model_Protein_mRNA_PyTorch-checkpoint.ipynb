{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae2d202",
   "metadata": {},
   "source": [
    "Pytorch Datasets and Dataloaders <br>\n",
    "    https://pytorch.org/tutorials/beginner/basics/data_tutorial.html <br>\n",
    "    https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cf72f",
   "metadata": {},
   "source": [
    "Installing Pytorch and preparing the environment: <br>\n",
    "From tool on Pytorch's installation website (https://pytorch.org/get-started/locally/) <br>\n",
    "Use the command: conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia <br>\n",
    "Will also need to install pandas, matplotlib, scikit-learn (sklearn), and seaborn with conda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364894e",
   "metadata": {},
   "source": [
    "The subcellular localization data is the neighborhood annotations for MCF7 cells from Orre et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pdb import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL #for images\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchvision.transforms import Resize\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications\n",
    "\n",
    "# Data splitting and path\n",
    "ImagePathString = '/home/ubuntu/NeuralNetworks/Gene_Images/Krug_18by18Grid'\n",
    "path2 = Path(ImagePathString)\n",
    "ValFrac = 0.3\n",
    "\n",
    "# Training and Validation Data Sets\n",
    "ImageTransformationName = 'None'\n",
    "ShuffleLabels = False\n",
    "#   if you want to shuffle the labels to see if a model is actually training\n",
    "\n",
    "if ImageTransformationName == 'GaussianBlur':\n",
    "    blur_sigma = (1.1,1.1)\n",
    "    # (0.9,0.9) is a decent value\n",
    "    \n",
    "# Model\n",
    "ModelWeightSpefication = 'random'\n",
    "if ModelWeightSpefication == 'random':\n",
    "    ModelWeights = None\n",
    "if ModelWeightSpefication == 'pretrained':\n",
    "    ModelWeights = models.ResNet50_Weights.DEFAULT\n",
    "    # models.ResNet50_Weights.DEFAULT is some pretrained set of values\n",
    "\n",
    "# Optimizer\n",
    "Weight_Decay = 0.0\n",
    "#  penalizes for too many weights - helps prevent overfitting\n",
    "Momentum = 0.9\n",
    "#  a way to smooth noise that is passed to the optimizer, 0.9\n",
    "#  momentum is deterimental without label smoothing\n",
    "learner_rate = 5e-4\n",
    "# 1e-3 seems to work well\n",
    "\n",
    "# Loss Function\n",
    "Label_Smoothing = 0.1\n",
    "#  was 0.1\n",
    "#  sets the target of the loss function to something greater than 0 and less than 1\n",
    "#  helps prevent overfitting\n",
    "AddLayerForWeights = True\n",
    "# Makes the loss weights equal to the fraction of each category label\n",
    "# Note, a layer is added to the model so the outputs of the model are equal to the number of categories\n",
    "#     This seems like a bug becuase that should already be the case\n",
    "\n",
    "# Run the model\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f35df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the GPU is available and store it as a variable so tensors can be moved to it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print('Is cuda available?:', torch.cuda.is_available())\n",
    "print('cuda version:', torch.version.cuda)\n",
    "dev = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary classes and functions\n",
    "\n",
    "# Create the CustomImageDataset class from the parent Dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_DF, img_dir, transform=None, target_transform=None,ImageExtension='.png'):\n",
    "        self.img_labels = annotations_DF\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.ImageExtension = ImageExtension\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] + self.ImageExtension)\n",
    "        image = read_image(img_path)\n",
    "        #image = PIL.Image.open(img_path)\n",
    "        #    attempt to get around byte vs. float problem: https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "        #image = image.double()\n",
    "        #image = plt.imread(img_path)\n",
    "        #  used in troubleshooting torchvision vs matplatlib formats\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "# Create a function to output training and validation annotation data frames from a single annotations file\n",
    "def GetTrainValAnnotDataFrames(annotations_file,img_dir,val_frac,ShuffleLabels=False):\n",
    "    # Inputs:\n",
    "    # annotations_file: a directory to an comma separated file with image filenames and their labels\n",
    "    # img_dir: a directory to the folder containing the image files\n",
    "    # val_frac: the fraction of samples used for validation\n",
    "    \n",
    "    # read the csv file with the sample annotations\n",
    "    annotationsDF = pd.read_csv(annotations_file,header=None,sep='\\t',dtype=str)\n",
    "    \n",
    "    # read the directory containing the images to get a list of filenames\n",
    "    #     strip the file extension so the filenames match the annotations in annotationsDF\n",
    "    FileList = os.listdir(img_dir)\n",
    "    Files_Without_Extension = [os.path.splitext(file)[0] for file in FileList]\n",
    "    \n",
    "    # remove entries in the annotationsDF that are not in the list of images\n",
    "    #     this is done so that the training and validation sets are divided correctly\n",
    "    OverlappingIndices = [item in Files_Without_Extension for item in annotationsDF.iloc[:,0]]\n",
    "    annotationsDF = annotationsDF.loc[OverlappingIndices,:]\n",
    "\n",
    "    # Shuffle the labels if indicated to do so\n",
    "    if ShuffleLabels:\n",
    "        LabelList = annotationsDF.iloc[:,1].tolist()\n",
    "        RandomLabels = copy.copy(LabelList)\n",
    "        random.shuffle(RandomLabels)\n",
    "        annotationsDF.iloc[:,1] = RandomLabels\n",
    "     \n",
    "    # remove unclassified indices for Zhuoheng's images (should not have to, but loss function does not have 5 when left in)\n",
    "    # NotUnclassifiedRowIndices = annotationsDF.iloc[:,1]!='Unclassified'\n",
    "    # annotationsDF = annotationsDF.loc[NotUnclassifiedRowIndices,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    unique_labels = np.unique(annotationsDF.iloc[:,1])\n",
    "    ValidationDF = pd.DataFrame()\n",
    "    TrainingDF = pd.DataFrame()\n",
    "    for label in unique_labels:\n",
    "        Subset_DF = annotationsDF.loc[annotationsDF.iloc[:,1]==label,:]\n",
    "        n_validation = int(np.floor(val_frac * len(Subset_DF.iloc[:,0])))\n",
    "        Validation_Subset = Subset_DF.sample(n=n_validation,ignore_index=True,random_state=42)\n",
    "        ValidationDF = pd.concat(objs=[ValidationDF,Validation_Subset],axis=0)\n",
    "        \n",
    "    Training_rows = [gene not in ValidationDF.iloc[:,0].to_numpy() for gene in annotationsDF.iloc[:,0].to_numpy()]\n",
    "    TrainingDF = annotationsDF.loc[Training_rows,:]\n",
    "    \n",
    "    return(ValidationDF, TrainingDF, unique_labels)\n",
    "\n",
    "# Function to convert a torchvision tensor to the default format for matplotlib\n",
    "    # matplotlib.pyplot.imshow interprets an RGB vector as shape (N,M,3) \n",
    "    # torchvision.io.read_image reads an RGB image as shape (3,N,M)\n",
    "def ShowTorchvisionImage(ImageTensor):\n",
    "    ImageTensor_t1 = ImageTensor.transpose(1,2)\n",
    "    ImageTensor_t2 = ImageTensor_t1.transpose(0,2)\n",
    "    plt.imshow(ImageTensor_t2)\n",
    "    \n",
    "def LabelArray_to_Tensor(input_array,labels_unique):\n",
    "    # converts a label array of strings to a tensor of floats\n",
    "    # Inputs:\n",
    "    #   input_array: the array of strings that are labels\n",
    "    #   labels_unique: an ordered list of the unique labels possible for the data set\n",
    "    # Outputs:\n",
    "    #   output_tensor: a tensor of floats, one unique float corresponding to each label\n",
    "    \n",
    "    int_label = np.arange(0,len(labels_unique))\n",
    "    i = 0\n",
    "    for label in labels_unique:\n",
    "        indices = [label == item for item in input_array]\n",
    "        input_array[indices] = int_label[i]\n",
    "        i = i+1\n",
    "\n",
    "    input_array = input_array.astype(float)\n",
    "    output_tensor = torch.as_tensor(input_array)\n",
    "    output_tensor = output_tensor.long()\n",
    "  \n",
    "    return(output_tensor)\n",
    "\n",
    "# Function for training the weights of the model\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "\n",
    "        \n",
    "        # convert to float32 to avoid error stating byte expected but found float\n",
    "        X = X.to(torch.float32)\n",
    "        X = X.to(dev)\n",
    "        pred = model(X)\n",
    "        \n",
    "        # convert the labels into a tensor of intigers and compute the loss\n",
    "        y = np.asarray(y)\n",
    "        y = LabelArray_to_Tensor(y,labels_unique)\n",
    "        y = y.to(dev)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "             \n",
    "\n",
    "    loss = loss.item()\n",
    "    return(loss)\n",
    "            \n",
    "# Function for validating the weights of the model\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # convert to float32 to avoid error stating byte expected but found float\n",
    "            X = X.to(torch.float32)\n",
    "            X = X.to(dev)\n",
    "            pred = model(X)\n",
    "            \n",
    "            # convert the labels into a tensor of intigers and compute the loss\n",
    "            y = np.asarray(y)\n",
    "            y = LabelArray_to_Tensor(y,labels_unique)\n",
    "            y = y.to(dev)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    return(test_loss,correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the samples up into training and validation\n",
    "Val_DF, Train_DF, unique_labels = GetTrainValAnnotDataFrames(annotations_file='../Label_Files/MCF7_SubCell_Barcode.txt',img_dir=path2,val_frac=ValFrac,ShuffleLabels=ShuffleLabels)\n",
    "labels_unique = np.unique(Train_DF.iloc[:,1])\n",
    "\n",
    "TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2)\n",
    "ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2)\n",
    "\n",
    "\n",
    "# Create the data sets with transformations from the training and validation set data frames defined above\n",
    "if ImageTransformationName == 'None':\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2)\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2)\n",
    "\n",
    "if ImageTransformationName == 'SpecifiedReorder':\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=SpecifiedReorder(sample_reorder_array))\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2,transform=SpecifiedReorder(sample_reorder_array))\n",
    "    \n",
    "if ImageTransformationName == 'GaussianBlur':\n",
    "    transform = T.GaussianBlur(kernel_size=(7, 13), sigma=blur_sigma)\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=transform)\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2,transform=transform)\n",
    "    \n",
    "if ImageTransformationName == 'RandomCrop':\n",
    "    transform = T.RandomCrop(size=(50, 50))\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=transform)\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2,transform=transform)\n",
    "\n",
    "    \n",
    "if ImageTransformationName == 'RandomRotation':\n",
    "    transform = T.RandomRotation(degrees=(-10, 10))\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=transform)\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2,transform=transform)\n",
    "    \n",
    "if ImageTransformationName == 'Resize':\n",
    "    transform = T.Resize(size=(50, 50))\n",
    "    TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=transform)\n",
    "    ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2,transform=transform)\n",
    "    \n",
    "# Other possible transformations\n",
    "#TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=Resize([224,224]))\n",
    "#TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2,transform=RandomPairReposition())\n",
    "\n",
    "# Define Data Loaders\n",
    "train_dataloader = DataLoader(TrainingData, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(ValData, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Check to see if the number of training data points plus validation data points sum to total data points\n",
    "print('sum of Val and Train Sets: ' + str(len(Val_DF.index)+len(Train_DF.index)))\n",
    "n_files = len(os.listdir(path2))\n",
    "print('num of samples: ' + str(n_files))\n",
    "\n",
    "# Display a training image and its corresponding label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "#print(f\"Feature batch shape: {train_features.size()}\")\n",
    "#print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "ShowTorchvisionImage(img)\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "# initial model weights\n",
    "model = models.resnet50(weights=ModelWeights)\n",
    "#model = models.resnet50() #without initial weights defined - good for patients not re-arranged\n",
    "\n",
    "# Add a final layer to the model where the output is equal to the number of classes (labels)\n",
    "#     This is required to use loss weights\n",
    "if AddLayerForWeights:\n",
    "    model.fc = nn.Sequential(\n",
    "        model.fc,\n",
    "        nn.Linear(1000, len(unique_labels))\n",
    "    )\n",
    "\n",
    "model = model.to(dev)\n",
    "\n",
    "# see the model architecture if desired\n",
    "#model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95869efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "# This needs to be made general for the number of classes\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if AddLayerForWeights:\n",
    "    # Weights for each class for loss function\n",
    "    n_cytosol = float(sum(TrainingData.img_labels.iloc[:,1]=='Cytosol'))\n",
    "    n_mitochondria = float(sum(TrainingData.img_labels.iloc[:,1]=='Mitochondria'))\n",
    "    n_nuclear = float(sum(TrainingData.img_labels.iloc[:,1]=='Nuclear'))\n",
    "    n_secretory = float(sum(TrainingData.img_labels.iloc[:,1]=='Secretory'))\n",
    "    #n_unclassified = float(sum(TrainingData.img_labels.iloc[:,1]=='Unclassified'))\n",
    "    n_total = len(TrainingData.img_labels.iloc[:,1])\n",
    "    LossWeights = (torch.tensor([n_cytosol,n_mitochondria,n_nuclear,n_secretory])/n_total)**-1\n",
    "    LossWeights = LossWeights.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=Label_Smoothing,weight=LossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learner_rate, weight_decay=Weight_Decay, momentum=Momentum)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learner_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "PerformanceDF = pd.DataFrame(index=range(epochs),columns=['Epoch','TrainLoss','ValLoss','TrainAcc','ValAcc'])\n",
    "print(f\"{'Epoch':>5s}{'Train Loss':>13s}{'Val Loss':>11s}{'Train Accuracy':>17s}{'Val Accuracy':>15s}\\n\")\n",
    "\n",
    "\n",
    "# The epoch of index 0 is before the first epoch - the model has not trained at all\n",
    "#   note: the result after the last epoch is not recorded or printed\n",
    "for t in range(epochs): \n",
    "    #train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_loss,val_accuracy = test_loop(val_dataloader, model, loss_fn)\n",
    "    train_loss2,train_accuracy = test_loop(train_dataloader, model, loss_fn)\n",
    "    Epoch = t\n",
    "    print(f\"{str(Epoch):>5s}{train_loss2:>13f}{val_loss:>11f}{train_accuracy*100:>16f}%{val_accuracy*100:>14f}%\")\n",
    "    PerformanceDF.loc[t,:]=[Epoch,train_loss2,val_loss,train_accuracy*100,val_accuracy*100]\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    # note: I am not sure how to load the MSD into the model\n",
    "    if Epoch == 0:\n",
    "        highest_val_accuracy = 0 \n",
    "        MSD0 = copy.deepcopy(model.state_dict())\n",
    "    if val_accuracy > highest_val_accuracy:\n",
    "        highest_val_accuracy = val_accuracy\n",
    "        MSD_Best = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c52a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracies as a function of the epoch number\n",
    "\n",
    "# Convert to a long data frame\n",
    "LongDF = pd.melt(frame=PerformanceDF,value_vars=['ValAcc','TrainAcc'],id_vars='Epoch')\n",
    "\n",
    "# Make and format the plot\n",
    "plot = sns.lineplot(data=LongDF,x='Epoch',y='value',hue='variable')\n",
    "sns.despine(bottom = False, left = False)\n",
    "plot.set(ylim=(0, None))\n",
    "plot.set(xlim=(0, 70))\n",
    "vals = plot.get_yticks()\n",
    "plot.set_yticklabels(plot.get_yticks(), size = 15)\n",
    "plot.set_xticklabels(plot.get_xticks(), size = 15)\n",
    "plot.set_yticklabels(['{:.0f}%'.format(x) for x in vals])\n",
    "#plot.set_xticklabels(['{}'.format(int(x)) for x in domains])\n",
    "\n",
    "if not ShuffleLabels:\n",
    "    plt.savefig(\"../outputs/TrueLabels_LineTrace.pdf\", format='pdf')\n",
    "\n",
    "if ShuffleLabels:\n",
    "    plt.savefig(\"../outputs/ShuffledLabels_LineTrace.pdf\", format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2885ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best recorded epoch validation accuracy: ' + str(round(100*highest_val_accuracy,2)))\n",
    "\n",
    "BestModel = copy.deepcopy(model)\n",
    "BestModel.load_state_dict(MSD_Best)\n",
    "val_loss,best_val_accuracy = test_loop(val_dataloader, BestModel, loss_fn)\n",
    "print('Best epoch recalculated validation accuracy: ' + str(round(100*best_val_accuracy,2)))\n",
    "\n",
    "FirstModel = copy.deepcopy(model)\n",
    "FirstModel.load_state_dict(MSD0)\n",
    "val_loss,first_val_accuracy = test_loop(val_dataloader, FirstModel, loss_fn)\n",
    "print('First epoch validation Accuracy: ' + str(round(100*first_val_accuracy,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d81571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build confusion matrix\n",
    "#   https://christianbernecker.medium.com/how-to-create-a-confusion-matrix-in-pytorch-38d06a7f04b7\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for X, y in val_dataloader:\n",
    "    \n",
    "        X = X.to(torch.float32)\n",
    "        X = X.to(dev)\n",
    "        output = model(X) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        output_string = [unique_labels[i] for i in output]\n",
    "        \n",
    "        y_pred.extend(output_string) # Save Prediction\n",
    "        \n",
    "        labels = y\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = unique_labels\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cf_matrix_norm = np.zeros((len(classes),len(classes)))\n",
    "for i in np.arange(0,len(classes)):\n",
    "    cf_matrix_norm[i,:] = cf_matrix[i,:]/sum(cf_matrix[i,:])\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix_norm, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (6,5))\n",
    "hm = sn.heatmap(df_cm, annot=True)\n",
    "hm.set(xlabel='\\n\\nPrediction', ylabel='Label\\n\\n')\n",
    "\n",
    "\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Orientation of Confusion Matrix\n",
    "#     Data labels go down the rows and predictions label the columns\n",
    "\n",
    "# Print Confusion Matrix Row Sums\n",
    "ConfusionMatrix_RowSums = [sum(cf_matrix[i,:]) for i in np.arange(0,len(unique_labels))]\n",
    "print(ConfusionMatrix_RowSums)\n",
    "\n",
    "# Print Quantity of Items with each label\n",
    "ValDF_UniqueLabelSums = [sum(Val_DF.iloc[:,1]==classes[i]) for i in np.arange(0,len(unique_labels))]\n",
    "print(ValDF_UniqueLabelSums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5d55e",
   "metadata": {},
   "source": [
    "Old Stuff Below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for transforming the input image by a specified reordering of adjacent pairs\n",
    "\n",
    "\n",
    "# The custom class must have the parent class of object because that is what is expected by the CustomImageDataset object\n",
    "class SpecifiedReorder(object):\n",
    "    \n",
    "    def __init__(self,InputOrder):\n",
    "#         self.img = InputTensor\n",
    "         self.ReOrder = InputOrder\n",
    "#         self.NewImage = self.transform()\n",
    "    \n",
    "    # The InputTensor is what is passed to the call of the class - this is probably behaviour of the object parent class\n",
    "    def __call__(self,InputTensor):\n",
    "        # Krista\n",
    "        # Inputs:\n",
    "        #   InputTensor: An n x n x 3 tensor\n",
    "        #   InputOrder: An array of length (n x n)/2\n",
    "\n",
    "        # Outputs:\n",
    "        #   A n x n x 3 tensor where each n x n layer has been reordered in the same way\n",
    "        #     consecutive pairs have been placed in the specified locations, still next to each other and both on the same row\n",
    "        \n",
    "        \n",
    "        # Determine the number of measurements in the tensor\n",
    "        TensorDimensions = np.shape(InputTensor)\n",
    "        array_n = TensorDimensions[1] * TensorDimensions[2]\n",
    "        matrices_n = TensorDimensions[0]\n",
    "\n",
    "        # Specify the desired order of samples\n",
    "        sample_order = self.ReOrder\n",
    "        sample_order_indices = 2*sample_order\n",
    "\n",
    "        \n",
    "        TransformedArray = np.zeros((InputTensor.size()[0],InputTensor.size()[1],InputTensor.size()[2]))\n",
    "        TransformedArray = TransformedArray.astype(np.uint8)\n",
    "\n",
    "        for matrix_i in np.arange(0,matrices_n):\n",
    "\n",
    "            # Define the matrix to transform\n",
    "            matrix = InputTensor[matrix_i]\n",
    "\n",
    "            # Convert the matrix to an array\n",
    "            array = np.array(matrix.flatten())\n",
    "\n",
    "            # initialize the full diagonal of the transformation matrix\n",
    "            reordered_indices = np.zeros(array_n)\n",
    "            for i in np.arange(array_n/2):\n",
    "                i = i.astype(int)\n",
    "                # the first index in a pair will be from the randomly ordered even indices\n",
    "                reordered_indices[2*i] = sample_order_indices[i]\n",
    "                # the second index in a pair will be the odd number one above the even index number\n",
    "                reordered_indices[2*i+1] = sample_order_indices[i] + 1\n",
    "\n",
    "            # Convert indices to values in the original array\n",
    "            transformed_array = np.array([array[int(i)] for i in reordered_indices])\n",
    "\n",
    "            # Convert the array back to a torch tensor with its original shape and data type\n",
    "            array_2D = np.reshape(transformed_array,np.shape(matrix))\n",
    "            array_2D = array_2D.astype(np.uint8)\n",
    "            TransformedArray[matrix_i,] = array_2D\n",
    "\n",
    "        TransformedTensor = torch.from_numpy(TransformedArray)\n",
    "        #self.NewImage = TransformedTensor\n",
    "\n",
    "        return(TransformedTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc07473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform image\n",
    "#   Randomly repositions adjacent pairs of pixels\n",
    "#   Done so model does not use patient order\n",
    "def RandomPairRepositionFunc(InputTensor):\n",
    "    # Krista\n",
    "    # Inputs:\n",
    "    #   A n x n x 3 tensor\n",
    "\n",
    "    # Outputs:\n",
    "    #   A n x n x 3 tensor where each n x n layer has been reordered in the same way\n",
    "    #     consecutive pairs have been randomly placed in a different location, still next to each other and both on the same row\n",
    "\n",
    "    # Determine the number of measurements in the tensor\n",
    "    TensorDimensions = np.shape(InputTensor)\n",
    "    array_n = TensorDimensions[1] * TensorDimensions[2]\n",
    "    matrices_n = TensorDimensions[0]\n",
    "\n",
    "    # initialize an array to be the diagonal of the transformation matrix\n",
    "    diagonal_n = int(array_n/2)\n",
    "\n",
    "    # fill in the diagonal array numerators as randomly ordered indices from 0 to 1/2 the number of indices in data array\n",
    "    #     multiply randomly selected indices by 2 because random indices are the first in random adjacent paris selected from the data array\n",
    "    diagonal = 2*np.random.choice(np.arange(array_n/2), size=diagonal_n, replace=False, p=None)\n",
    "\n",
    "\n",
    "    TransformedArray = np.zeros((3,14,14))\n",
    "    TransformedArray = TransformedArray.astype(np.uint8)\n",
    "\n",
    "    for matrix_i in np.arange(0,matrices_n):\n",
    "\n",
    "        # Define the matrix to transform\n",
    "        matrix = InputTensor[matrix_i]\n",
    "\n",
    "        # Convert the matrix to an array\n",
    "        array = np.array(matrix.flatten())\n",
    "\n",
    "        # initialize the full diagonal of the transformation matrix\n",
    "        diagonal2 = np.zeros(array_n)\n",
    "        for i in np.arange(array_n/2):\n",
    "            i = i.astype(int)\n",
    "            # the first index in a pair will be from the randomly ordered even indices\n",
    "            diagonal2[2*i] = diagonal[i]\n",
    "            # the second index in a pair will be the odd number one above the even index number\n",
    "            diagonal2[2*i+1] = diagonal[i] + 1\n",
    "\n",
    "        # Convert indices to values in the original array\n",
    "        diagonal_values = np.array([array[int(i)] for i in diagonal2])\n",
    "\n",
    "        # Perform elementwise division of the re-ordered values taken from the original array with the original values in their original order\n",
    "        diagonal_values2 = np.divide(diagonal_values,array)\n",
    "\n",
    "        # Build the transormation matrix by setting the above values as the diagonal with all other values 0 in a square matrix\n",
    "        CoefficientMatrix = np.zeros((array_n,array_n))\n",
    "        np.fill_diagonal(CoefficientMatrix,diagonal_values2)\n",
    "\n",
    "        # Transform the original data array\n",
    "        transformed_array = np.matmul(array,CoefficientMatrix)\n",
    "\n",
    "        # Convert the array back to a torch tensor with its original shape and data type\n",
    "        array_2D = np.reshape(transformed_array,np.shape(matrix))\n",
    "        array_2D = array_2D.astype(np.uint8)\n",
    "        TransformedArray[matrix_i,] = array_2D\n",
    "\n",
    "    TransformedTensor = torch.from_numpy(TransformedArray)\n",
    "\n",
    "    return(TransformedTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd478e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the distance between two adjacent points in an image \n",
    "#   The image is specified by a 3D tensor\n",
    "def DistCalc(Tensor,k,j):\n",
    "    # Inputs:\n",
    "    #   k specifies which pair within a column\n",
    "    #   j specifies the row\n",
    "    #   Tensor is the input image 3D tensor\n",
    "    \n",
    "    col = 2*k\n",
    "    term1 = (Tensor[0][j][col].double() - Tensor[0][j][col+1].double())**2\n",
    "    term2 = (Tensor[1][j][col].double() - Tensor[1][j][col+1].double())**2\n",
    "    term3 = (Tensor[2][j][col].double() - Tensor[2][j][col+1].double())**2\n",
    "    dist = (term1 + term2 + term3)**0.5\n",
    "    dist_float = dist.item()\n",
    "    return(dist_float)\n",
    "\n",
    "# Split the samples up into training and validation\n",
    "Val_DF, Train_DF, unique_labels = GetTrainValAnnotDataFrames(annotations_file='MCF7_SubCell_Barcode.txt',img_dir=path2,val_frac=ValFrac)\n",
    "labels_unique = np.unique(Train_DF.iloc[:,1])\n",
    "\n",
    "TrainingData = CustomImageDataset(annotations_DF=Train_DF,img_dir=path2)\n",
    "ValData = CustomImageDataset(annotations_DF=Val_DF,img_dir=path2)\n",
    "\n",
    "# Compute the distances between protein and mRNA expression values for every gene across all patients\n",
    "#     each gene correpsonds to an image\n",
    "#     each patient corresponds to a protein-mRNA pixel pair in the image\n",
    "\n",
    "n_images = len(TrainingData)+len(ValData)\n",
    "n_TrnData = len(TrainingData)\n",
    "n_pixels_edge = np.shape(TrainingData[0][0])[1]\n",
    "n_pixels = np.shape(TrainingData[0][0])[1]*np.shape(TrainingData[0][0])[2]\n",
    "DistArray = np.zeros((int(n_pixels/2),n_images),dtype=float)\n",
    "for i in np.arange(0,n_images):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    if i < n_TrnData:\n",
    "        Tensor = TrainingData[i][0]\n",
    "    if i >= n_TrnData:\n",
    "        Tensor = ValData[i-n_TrnData][0]\n",
    "    DistTens0 = [DistCalc(Tensor,k,j) for j in np.arange(0,n_pixels_edge) for k in np.arange(0,int(n_pixels_edge/2))]\n",
    "    DistArray[:,i] = DistTens0\n",
    "\n",
    "# Compute the average protein-mRNA distance across genes for each patient\n",
    "AvgDistances = np.sum(DistArray,1)/n_images\n",
    "\n",
    "# Rank the patients from lowest to highest distance\n",
    "sample_reorder_array = np.argsort(AvgDistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowTorchvisionImage(RandomPairRepositionFunc(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(ImagePathString)\n",
    "len(file_list)\n",
    "file_list.sort()\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(ImagePathString+'/.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a046c",
   "metadata": {},
   "source": [
    "Got 40% accuracy with significant higher than null true positive rates for every category with weight decay = 0, momentum=0 and label weighting. 1e-3 learning rate until ~90% accurate on training data, then 1e-4 learning rate.\n",
    "\n",
    "Got a lower accuracy, but improved true positive rates for the other categories (not cytosol) when weight decay and momentum were added. Adding blur improved true positive rates and true negative rates, and slightly improved overall accuracy much (something to do with most genes being cytsolic and nuclear?). Blur sigma of (0.9,0.9) worked the best so far, but may continue to improve if I raise it more.\n",
    "\n",
    "Get hightest validation accuracy there are not transformations, when patients have not been re-ordered, there is no label smoothing or momentum, no layer is added to the model, and there are no weights on the loss function, and no default weights are passed to the model. (72-73%)\n",
    "\n",
    "Adding loss function weights works well too, brings accuracy to 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712b3d2",
   "metadata": {},
   "source": [
    "Notes on identifying Zhuoheng's pictures:\n",
    "- patient ID's provided by color\n",
    "-   44% accuracy after 10 epochs, with little improvement after 1st epoch (42% accuracy)\n",
    "-   bias towards cytosol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e803ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loads an arbitrary RGB image from the misc library\n",
    "rgbImg = img.detach().clone()\n",
    "img1 = copy.copy(img)\n",
    "\n",
    "#Display out the original RGB image\n",
    "#ShowTorchvisionImage(img)\n",
    "\n",
    "# doc on shuffle: multi-dimensional arrays are only shuffled along the first axis\n",
    "# so let's make the image an array of (N,3) instead of (m,n,3)\n",
    "\n",
    "rndImg2 = np.reshape(rgbImg, (rgbImg.shape[1] * rgbImg.shape[2], rgbImg.shape[0]))\n",
    "# this like could also be written using -1 in the shape tuple\n",
    "# this will calculate one dimension automatically\n",
    "# rndImg2 = np.reshape(rgbImg, (-1, rgbImg.shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "#now shuffle\n",
    "np.random.shuffle(rndImg2)\n",
    "\n",
    "#and reshape to original shape\n",
    "rdmImg = np.reshape(rndImg2, rgbImg.shape)\n",
    "\n",
    "ShowTorchvisionImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba47c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(img[0] != 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
